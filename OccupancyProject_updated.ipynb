{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Occupancy Project\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Occupancy Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyTraining=spark.read.json(\"OccupancyData_Train.json\",multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-------------------+---+-----+---------+-----------+-------------------+\n",
      "|             CO2|        Humidity|      HumidityRatio| ID|Light|Occupancy|Temperature|               date|\n",
      "+----------------+----------------+-------------------+---+-----+---------+-----------+-------------------+\n",
      "|          721.25|          27.272|0.00479298817650529|  1|426.0|        1|      23.18|2015-02-04 17:51:00|\n",
      "|           714.0|         27.2675|0.00478344094931065|  2|429.5|        1|      23.15|2015-02-04 17:51:59|\n",
      "|           713.5|          27.245|0.00477946352442199|  3|426.0|        1|      23.15|2015-02-04 17:53:00|\n",
      "|          708.25|            27.2|0.00477150882608175|  4|426.0|        1|      23.15|2015-02-04 17:54:00|\n",
      "|           704.5|            27.2|0.00475699293331518|  5|426.0|        1|       23.1|2015-02-04 17:55:00|\n",
      "|           701.0|            27.2|0.00475699293331518|  6|419.0|        1|       23.1|2015-02-04 17:55:59|\n",
      "|701.666666666667|            27.2|0.00475699293331518|  7|419.0|        1|       23.1|2015-02-04 17:57:00|\n",
      "|           699.0|            27.2|0.00475699293331518|  8|419.0|        1|       23.1|2015-02-04 17:57:59|\n",
      "|689.333333333333|            27.2|0.00475699293331518|  9|419.0|        1|       23.1|2015-02-04 17:58:59|\n",
      "|           688.0|          27.175|0.00474535071966655| 10|419.0|        1|     23.075|2015-02-04 18:00:00|\n",
      "|          690.25|           27.15|0.00474095189694268| 11|419.0|        1|     23.075|2015-02-04 18:01:00|\n",
      "|           691.0|            27.1|0.00473937073052061| 12|419.0|        1|       23.1|2015-02-04 18:02:00|\n",
      "|           683.5|27.1666666666667|0.00475111875560951| 13|419.0|        1|       23.1|2015-02-04 18:03:00|\n",
      "|           687.5|           27.15| 0.0047337317970825| 14|419.0|        1|      23.05|2015-02-04 18:04:00|\n",
      "|           686.0|          27.125|0.00471494214590473| 15|419.0|        1|       23.0|2015-02-04 18:04:59|\n",
      "|           680.5|          27.125|0.00471494214590473| 16|418.5|        1|       23.0|2015-02-04 18:06:00|\n",
      "|           681.5|            27.2|0.00472807794966877| 17|  0.0|        0|       23.0|2015-02-04 18:07:00|\n",
      "|           685.0|           27.29|0.00472795137178073| 18|  0.0|        0|     22.945|2015-02-04 18:08:00|\n",
      "|           685.0|           27.39| 0.0047454083970941| 19|  0.0|        0|     22.945|2015-02-04 18:08:59|\n",
      "|           689.0|           27.39|0.00472950615591001| 20|  0.0|        0|      22.89|2015-02-04 18:10:00|\n",
      "+----------------+----------------+-------------------+---+-----+---------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyTraining.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OccupancyTraining.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CO2: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- HumidityRatio: double (nullable = true)\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Light: double (nullable = true)\n",
      " |-- Occupancy: long (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyTraining.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyData_1=spark.read.option(\"delimiter\",\",\").option(\"inferSchema\",True).option(\"header\",True).csv(\"OccupancyData_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----------+--------+----------------+----------------+-------------------+---------+\n",
      "| ID|               date|Temperature|Humidity|           Light|             CO2|      HumidityRatio|Occupancy|\n",
      "+---+-------------------+-----------+--------+----------------+----------------+-------------------+---------+\n",
      "|140|2015-02-02 14:19:00|       23.7|  26.272|           585.2|           749.2|0.00476416302416414|        1|\n",
      "|141|2015-02-02 14:19:59|     23.718|   26.29|           578.4|           760.4|0.00477266099212519|        1|\n",
      "|142|2015-02-02 14:21:00|      23.73|   26.23|572.666666666667|769.666666666667|0.00476515255246541|        1|\n",
      "|143|2015-02-02 14:22:00|    23.7225|  26.125|          493.75|          774.75|0.00474377335599685|        1|\n",
      "|144|2015-02-02 14:23:00|     23.754|    26.2|           488.6|           779.0|0.00476659399998615|        1|\n",
      "|145|2015-02-02 14:23:59|      23.76|   26.26|568.666666666667|           790.0|0.00477933243163454|        1|\n",
      "|146|2015-02-02 14:25:00|      23.73|   26.29|536.333333333333|           798.0|0.00477613633274892|        1|\n",
      "|147|2015-02-02 14:25:59|     23.754|   26.29|           509.0|           797.0|0.00478309370839038|        1|\n",
      "|148|2015-02-02 14:26:59|     23.754|   26.35|           476.0|           803.2|0.00479409399662041|        1|\n",
      "|149|2015-02-02 14:28:00|     23.736|   26.39|           510.0|           809.0|0.00479618871038935|        1|\n",
      "|150|2015-02-02 14:29:00|     23.745|  26.445|           481.5|          815.25|0.00480888622067716|        1|\n",
      "|151|2015-02-02 14:30:00|       23.7|   26.56|           481.8|           824.0| 0.0048167933677358|        1|\n",
      "|152|2015-02-02 14:31:00|       23.7|    26.6|          475.25|           832.0|0.00482410383674874|        1|\n",
      "|153|2015-02-02 14:31:59|       23.7|    26.7|           469.0|845.333333333333|0.00484238075533563|        1|\n",
      "|154|2015-02-02 14:32:59|       23.7|  26.774|           464.0|           852.4|0.00485590636128976|        1|\n",
      "|155|2015-02-02 14:34:00|       23.7|   26.89|           464.0|           861.0|0.00487710983719076|        1|\n",
      "|156|2015-02-02 14:35:00|       23.7| 26.9725|           455.0|           880.0|  0.004892190768364|        1|\n",
      "|157|2015-02-02 14:36:00|       23.6|   26.89|           454.0|           891.0|0.00484759441396992|        1|\n",
      "|158|2015-02-02 14:37:00|      23.64|  26.976|           458.0|           897.6| 0.0048750447811301|        1|\n",
      "|159|2015-02-02 14:38:00|      23.65|   27.05|           464.0|           900.5|0.00489149158929623|        1|\n",
      "+---+-------------------+-----------+--------+----------------+----------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- Light: double (nullable = true)\n",
      " |-- CO2: double (nullable = true)\n",
      " |-- HumidityRatio: double (nullable = true)\n",
      " |-- Occupancy: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OccupancyData_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyData_2=spark.read.csv(\"OccupancyData_2.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-----------+-----------+-----------+-----------+-------------+---------+\n",
      "| ID|           Date|Temperature|   Humidity|      Light|        CO2|HumidityRatio|Occupancy|\n",
      "+---+---------------+-----------+-----------+-----------+-----------+-------------+---------+\n",
      "|  1|2/11/2015 14:48|      21.76|31.13333333|437.3333333|1029.666667|  0.005021011|        1|\n",
      "|  2|2/11/2015 14:49|      21.79|       31.0|437.3333333|     1000.0|  0.005008581|        1|\n",
      "|  3|2/11/2015 14:50|    21.7675|    31.1225|      434.0|    1003.75|  0.005021569|        1|\n",
      "|  4|2/11/2015 14:51|    21.7675|    31.1225|      439.0|     1009.5|  0.005021569|        1|\n",
      "|  5|2/11/2015 14:51|      21.79|31.13333333|437.3333333|1005.666667|  0.005030298|        1|\n",
      "|  6|2/11/2015 14:53|      21.76|      31.26|437.3333333|1014.333333|  0.005041605|        1|\n",
      "|  7|2/11/2015 14:54|      21.79|    31.1975|      434.0|     1018.5|  0.005040749|        1|\n",
      "|  8|2/11/2015 14:55|      21.79|31.39333333|437.3333333|1018.666667|  0.005072649|        1|\n",
      "|  9|2/11/2015 14:55|      21.79|    31.3175|      434.0|     1022.0|  0.005060296|        1|\n",
      "| 10|2/11/2015 14:57|      21.79|31.46333333|437.3333333|1027.333333|  0.005084053|        1|\n",
      "| 11|2/11/2015 14:57|      21.79|     31.525|     437.75|    1047.75|  0.005094099|        1|\n",
      "| 12|2/11/2015 14:58|      21.79|     31.575|     441.75|     1049.0|  0.005102244|        1|\n",
      "| 13|2/11/2015 15:00|      21.79|     31.395|      442.0|     1061.5|  0.005072921|        1|\n",
      "| 14|2/11/2015 15:01|      21.79|    31.3925|     441.75|     1049.0|  0.005072514|        1|\n",
      "| 15|2/11/2015 15:02|      21.79|       31.5|      441.5|     1048.0|  0.005090026|        1|\n",
      "| 16|2/11/2015 15:03|     21.815|       31.5|      438.0|    1049.25|  0.005097869|        1|\n",
      "| 17|2/11/2015 15:04|     21.815|    31.4725|      449.5|    1051.25|  0.005093382|        1|\n",
      "| 18|2/11/2015 15:04|      21.89|       31.6|      449.5|     1060.5|  0.005137857|        1|\n",
      "| 19|2/11/2015 15:06|      21.79|      31.55|      449.5|     1059.5|  0.005098172|        1|\n",
      "| 20|2/11/2015 15:07|21.82333333|      31.73|447.6666667|     1072.0|  0.005138035|        1|\n",
      "+---+---------------+-----------+-----------+-----------+-----------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- Light: double (nullable = true)\n",
      " |-- CO2: double (nullable = true)\n",
      " |-- HumidityRatio: double (nullable = true)\n",
      " |-- Occupancy: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9752"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OccupancyData_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyTraining=OccupancyTraining.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('Light',2).cast(\"double\").alias('Light'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyTraining['Occupancy'].cast(\"int\").alias('label'))\n",
    "OccupancyData_1=OccupancyData_1.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('Light',2).cast(\"double\").alias('Light'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyData_1['Occupancy'].cast(\"int\").alias('label'))\n",
    "OccupancyData_2=OccupancyData_2.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('Light',2).cast(\"double\").alias('Light'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyData_2['Occupancy'].cast(\"int\").alias('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccupancyTraining=OccupancyTraining.na.drop()\n",
    "OccupancyData_1=OccupancyData_1.na.drop()\n",
    "OccupancyData_2=OccupancyData_2.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- Light: double (nullable = true)\n",
      " |-- CO2: double (nullable = true)\n",
      " |-- HumidityRatio: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyTraining.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(OccupancyData_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(OccupancyData_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(OccupancyTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to Occupancy for  ID -0.19163701371848915\n",
      "Correlation to Occupancy for  Temperature 0.40960481158547857\n",
      "Correlation to Occupancy for  Humidity -0.13350890620500191\n",
      "Correlation to Occupancy for  Light 0.8820928406674347\n",
      "Correlation to Occupancy for  CO2 0.75170933077023\n",
      "Correlation to Occupancy for  HumidityRatio -0.017548012702666926\n",
      "Correlation to Occupancy for  label 1.0\n"
     ]
    }
   ],
   "source": [
    "##Reference from https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a\n",
    "import six\n",
    "for i in OccupancyTraining.columns:\n",
    "    if not( isinstance(OccupancyTraining.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to Occupancy for \", i, OccupancyTraining.stat.corr('label',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|       Temperature|          Humidity|             Light|               CO2|              label|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|              7165|              7165|              7165|              7165|               7165|\n",
      "|   mean|20.457959525471075|24.852009769714208| 81.35663503140277|508.43546685275646|0.12826238660153524|\n",
      "| stddev|0.9565506592085856| 5.043850267875856|163.55525063028136|134.18720594948988|0.33440507494290406|\n",
      "|    min|              19.0|             16.75|               0.0|            412.75|                  0|\n",
      "|    max|             23.18|             36.26|             829.0|             999.0|                  1|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyTraining.describe('Temperature','Humidity','Light','CO2','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|       Temperature|          Humidity|             Light|               CO2|              label|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|              2067|              2067|              2067|              2067|               2067|\n",
      "|   mean|21.059279148524148|24.371432027092276| 108.9514368650217| 585.4530430575707|0.20029027576197386|\n",
      "| stddev|0.7939853845424611|1.6004914179389853|201.91197481234178|167.11204968734683|0.40031438869227154|\n",
      "|    min|              20.2|              22.1|               0.0|             427.5|                  0|\n",
      "|    max|             23.76|              29.0|             767.0|            999.75|                  1|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_1.describe('Temperature','Humidity','Light','CO2','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|       Temperature|          Humidity|             Light|               CO2|              label|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|              8238|              8238|              8238|              8238|               8238|\n",
      "|   mean|20.950000000001527|29.803625880069504|113.21782592862333| 641.4921680019422|0.17953386744355426|\n",
      "| stddev|1.0760576474807138| 4.046180998418582|202.65785596884305|131.81652669304634| 0.3838220170672848|\n",
      "|    min|              19.5|             21.86|               0.0|            484.67|                  0|\n",
      "|    max|             24.39|              39.5|            820.67|            999.75|                  1|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_2.describe('Temperature','Humidity','Light','CO2','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- Light: double (nullable = true)\n",
      " |-- CO2: double (nullable = true)\n",
      " |-- HumidityRatio: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OccupancyData_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[23.18,27.27,426....|    1|\n",
      "|[23.15,27.27,429....|    1|\n",
      "|[23.15,27.25,426....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio'], outputCol = 'features')\n",
    "OT = vectorAssembler.transform(OccupancyTraining)\n",
    "OT = OT.select(['features', 'label'])\n",
    "OT.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_log_reg_model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_logreg_model= my_log_reg_model.fit(OT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary=fitted_logreg_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[23.18,27.27,426....|  1.0|[0.45837158904843...|[0.61262780077768...|       0.0|\n",
      "|[23.15,27.27,429....|  1.0|[0.40238549679144...|[0.59926066618222...|       0.0|\n",
      "|[23.15,27.25,426....|  1.0|[0.48664768944087...|[0.61931639628840...|       0.0|\n",
      "|[23.15,27.2,426.0...|  1.0|[0.53007360241976...|[0.62950027839966...|       0.0|\n",
      "|[23.1,27.2,426.0,...|  1.0|[0.49281340121340...|[0.62076897345756...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.67607912841527...|[0.66286303844105...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.67059953329719...|[0.66163739173683...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.69243612876775...|[0.66650863643600...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.77152222547196...|[0.68385008964677...|       0.0|\n",
      "|[23.07,27.18,419....|  1.0|[0.74100503510602...|[0.67721559063805...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[23.7,26.27,585.2...|    1|\n",
      "|[23.72,26.29,578....|    1|\n",
      "|[23.73,26.23,572....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio'], outputCol = 'features')\n",
    "OTest1 = vectorAssembler.transform(OccupancyData_1)\n",
    "OTest1 = OTest1.select(['features', 'label'])\n",
    "OTest1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_labels=fitted_logreg_model.evaluate(OTest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[23.7,26.27,585.2...|    1|[-2.5018278116556...|[0.07573014292761...|       1.0|\n",
      "|[23.72,26.29,578....|    1|[-2.4145906931294...|[0.08206682848919...|       1.0|\n",
      "|[23.73,26.23,572....|    1|[-2.3467561111768...|[0.08732395961205...|       1.0|\n",
      "|[23.72,26.12,493....|    1|[-0.6540882709716...|[0.34206884708097...|       1.0|\n",
      "|[23.75,26.2,488.6...|    1|[-0.5397204885433...|[0.36825260614773...|       1.0|\n",
      "|[23.76,26.26,568....|    1|[-2.3865236377872...|[0.08420612594091...|       1.0|\n",
      "|[23.73,26.29,536....|    1|[-1.7810349258926...|[0.14417538874781...|       1.0|\n",
      "|[23.75,26.29,509....|    1|[-1.1457663719854...|[0.24126322186670...|       1.0|\n",
      "|[23.75,26.35,476....|    1|[-0.4728962571687...|[0.38393096786454...|       1.0|\n",
      "|[23.74,26.39,510....|    1|[-1.2808599460000...|[0.21740387729769...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_and_labels.predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_roc = my_eval.evaluate(prediction_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904930575647849"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_roc ## area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[21.89,31.12,432....|    0|\n",
      "|[21.89,31.15,436....|    1|\n",
      "|[21.89,31.06,434....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio'], outputCol = 'features')\n",
    "OTest2 = vectorAssembler.transform(OccupancyData_2)\n",
    "OTest2 = OTest2.select(['features', 'label'])\n",
    "OTest2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_labels_2=fitted_logreg_model.evaluate(OTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_roc_2 = my_eval.evaluate(prediction_and_labels_2.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950995147231907"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_roc_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing Light column as it has high correlation with Occupancy\n",
    "OccupancyTraining_N=OccupancyTraining.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyTraining['label'].cast(\"int\").alias('label'))\n",
    "OccupancyData_1_N=OccupancyData_1.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyData_1['label'].cast(\"int\").alias('label'))\n",
    "OccupancyData_2_N=OccupancyData_2.select('ID',format_number('Temperature',2).cast(\"double\").alias('Temperature'),format_number('Humidity',2).cast(\"double\").alias('Humidity'),format_number('CO2',2).cast(\"double\").alias('CO2'),format_number('HumidityRatio',10).cast(\"double\").alias('HumidityRatio'),OccupancyData_2['label'].cast(\"int\").alias('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to Occupancy for  ID -0.19163701371848915\n",
      "Correlation to Occupancy for  Temperature 0.40960481158547857\n",
      "Correlation to Occupancy for  Humidity -0.13350890620500191\n",
      "Correlation to Occupancy for  CO2 0.75170933077023\n",
      "Correlation to Occupancy for  HumidityRatio -0.017548012702666926\n",
      "Correlation to Occupancy for  label 1.0\n"
     ]
    }
   ],
   "source": [
    "##Reference from https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a\n",
    "import six\n",
    "for i in OccupancyTraining_N.columns:\n",
    "    if not( isinstance(OccupancyTraining_N.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to Occupancy for \", i, OccupancyTraining_N.stat.corr('label',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[23.18,27.27,721....|    1|\n",
      "|[23.15,27.27,714....|    1|\n",
      "|[23.15,27.25,713....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Temperature', 'Humidity', 'CO2', 'HumidityRatio'], outputCol = 'features')\n",
    "OT_N = vectorAssembler.transform(OccupancyTraining_N)\n",
    "OT_N = OT_N.select(['features', 'label'])\n",
    "OT_N.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_log_reg_model_N=LogisticRegression()\n",
    "fitted_logreg_model_N= my_log_reg_model_N.fit(OT_N)\n",
    "log_summary_N=fitted_logreg_model_N.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[23.7,26.27,749.2...|    1|\n",
      "|[23.72,26.29,760....|    1|\n",
      "|[23.73,26.23,769....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['Temperature', 'Humidity', 'CO2', 'HumidityRatio'], outputCol = 'features')\n",
    "OTest1_N = vectorAssembler.transform(OccupancyData_1_N)\n",
    "OTest1_N = OTest1_N.select(['features', 'label'])\n",
    "OTest1_N.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_labels_N=fitted_logreg_model_N.evaluate(OTest1_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_roc_N = my_eval.evaluate(prediction_and_labels_N.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904930575647849"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using Decision Trees\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer1 = StringIndexer(inputCol=\"label\", outputCol=\"PrivateIndex\")\n",
    "output_fixed_train = indexer1.fit(OT).transform(OT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = output_fixed_train.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer2 = StringIndexer(inputCol=\"label\", outputCol=\"PrivateIndex\")\n",
    "output_fixed_test = indexer2.fit(OTest1).transform(OTest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer3 = StringIndexer(inputCol=\"label\", outputCol=\"PrivateIndex\")\n",
    "output_fixed_test_2 = indexer3.fit(OTest2).transform(OTest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = output_fixed_test.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = output_fixed_test_2.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mostly defaults to make this comparison \"fair\"\n",
    "\n",
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "gbt = GBTClassifier(labelCol='PrivateIndex',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models (its three models, so it might take some time)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions_1 = dtc_model.transform(test_data_1)\n",
    "rfc_predictions_1 = rfc_model.transform(test_data_1)\n",
    "gbt_predictions_1 = gbt_model.transform(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"PrivateIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc_1 = acc_evaluator.evaluate(dtc_predictions_1)\n",
    "rfc_acc_1 = acc_evaluator.evaluate(rfc_predictions_1)\n",
    "gbt_acc_1 = acc_evaluator.evaluate(gbt_predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "--------------------------------------------------------------------------------\n",
      "A single decision tree had an accuracy of: 91.53%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble had an accuracy of: 92.45%\n",
      "--------------------------------------------------------------------------------\n",
      "A ensemble using GBT had an accuracy of: 92.55%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*80)\n",
    "print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "--------------------------------------------------------------------------------\n",
      "A single decision tree had an accuracy of: 91.49%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble had an accuracy of: 91.61%\n",
      "--------------------------------------------------------------------------------\n",
      "A ensemble using GBT had an accuracy of: 91.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc_1*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc_1*100))\n",
    "print('-'*80)\n",
    "print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbt_acc_1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[23.18,27.27,426....|  1.0|[0.45837158904843...|[0.61262780077768...|       0.0|\n",
      "|[23.15,27.27,429....|  1.0|[0.40238549679144...|[0.59926066618222...|       0.0|\n",
      "|[23.15,27.25,426....|  1.0|[0.48664768944087...|[0.61931639628840...|       0.0|\n",
      "|[23.15,27.2,426.0...|  1.0|[0.53007360241976...|[0.62950027839966...|       0.0|\n",
      "|[23.1,27.2,426.0,...|  1.0|[0.49281340121340...|[0.62076897345756...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.67607912841527...|[0.66286303844105...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.67059953329719...|[0.66163739173683...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.69243612876775...|[0.66650863643600...|       0.0|\n",
      "|[23.1,27.2,419.0,...|  1.0|[0.77152222547196...|[0.68385008964677...|       0.0|\n",
      "|[23.07,27.18,419....|  1.0|[0.74100503510602...|[0.67721559063805...|       0.0|\n",
      "|[23.07,27.15,419....|  1.0|[0.72164750091281...|[0.67296970478124...|       0.0|\n",
      "|[23.1,27.1,419.0,...|  1.0|[0.76456224667907...|[0.68234342635242...|       0.0|\n",
      "|[23.1,27.17,419.0...|  1.0|[0.82317429416121...|[0.69490973889492...|       0.0|\n",
      "|[23.05,27.15,419....|  1.0|[0.72168826424252...|[0.67297867597196...|       0.0|\n",
      "|[23.0,27.12,419.0...|  1.0|[0.66465304413993...|[0.66030485439214...|       0.0|\n",
      "|[23.0,27.12,418.5...|  1.0|[0.72068057915102...|[0.67275686762763...|       0.0|\n",
      "|[23.0,27.2,0.0,68...|  0.0|[9.95567765742972...|[0.99995254483150...|       0.0|\n",
      "|[22.95,27.29,0.0,...|  0.0|[9.85800658233042...|[0.99994767618346...|       0.0|\n",
      "|[22.95,27.39,0.0,...|  0.0|[9.85186021361246...|[0.99994735360861...|       0.0|\n",
      "|[22.89,27.39,0.0,...|  0.0|[9.73256452709674...|[0.99994068354750...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqData = log_summary.predictions.select('prediction', 'label').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = reqData.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreAndLabels = sc.parallelize(t.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(scoreAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6180.,   66.],\n",
       "       [  20.,  899.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
